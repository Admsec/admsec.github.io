<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/_posts/16107/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>nginx反代跳过网站备案</title>
    <url>/_posts/51114/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天搞了个国内的服务器，然后想搞个域名指向服务器，但是我身份证过期了，一星期前申请了换证还没那么快到，所以备案不了。</p>
<p>怎么办呢？</p>
<p>突然想起我有一台用学生认证白嫖的新加坡服务器，众所周知，域名指向国外的服务器是不用备案的，还可以加 https，所以我灵机一动：可以用域名指向新加坡的服务器，再用代理或者其他手段把该连接交给国内的服务器，就相当于用新加坡的服务器当跳板机，访问国内的服务器。</p>
<p>拓扑图如下</p>
<p><img src="https://img2.imgtp.com/2024/03/06/tXr5AzlG.png"></p>
<p>目前就想出来了两个方案：</p>
<ul>
<li>方案一：新加坡服务器安装 nginx，通过反向代理把请求连接转发给国内服务器</li>
<li>方案二：用 frp 内网穿透</li>
</ul>
<p>方案一我试过了是可行的，没有跨域的问题，网上查了下说别人也是主要用反向代理来解决跨域问题的；方案二的话还没试过，不知道。</p>
<h2 id="动手"><a href="#动手" class="headerlink" title="动手"></a>动手</h2><ol>
<li>首先国内服务器安装好博客，并能通过公网 IP 访问网站</li>
<li>新加坡服务器安装 nginx，我这里用的是包安装</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apt install nginx -y</span><br></pre></td></tr></table></figure>

<p>编辑配置文件，增加下面这一段</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    #SSL 访问端口号为 443</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">	#填写绑定证书的域名</span><br><span class="line">	server_name www.admsec.top;</span><br><span class="line"> 	#证书文件名称</span><br><span class="line">    ssl_certificate /opt/cert/xxx.xxx.xxx.pem;</span><br><span class="line"> 	#私钥文件名称</span><br><span class="line">    ssl_certificate_key /opt/cert/xxx.xxx.xxx.key;</span><br><span class="line">    ssl_session_timeout 5m;</span><br><span class="line"> 	#请按照以下协议配置</span><br><span class="line">    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line"> 	#请按照以下套件配置，配置加密套件，写法遵循 openssl 标准。</span><br><span class="line">    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;</span><br><span class="line">    ssl_prefer_server_ciphers on;</span><br><span class="line">    location / &#123;</span><br><span class="line">        #配置反向代理  因为hexo默认端口为4000，故使其指向</span><br><span class="line">        proxy_pass http://xxx.xxx.xxx.xxx/;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">	listen 80;</span><br><span class="line">	#填写绑定证书的域名</span><br><span class="line">	server_name xxx.xxx.xxx;</span><br><span class="line">	#把http的域名请求转成https</span><br><span class="line">	return 301 https://xxx.xxx.xxx;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>启动 nginx，成功！</li>
</ol>
]]></content>
      <tags>
        <tag>nginx</tag>
        <tag>反向代理</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫的噩梦—gzip炸弹</title>
    <url>/_posts/26628/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>有一些网站服务器可能使用 gzip 压缩网站资源，这些资源在网络传输上是压缩后二进制的形式，当网站头部有一个”Content-Encoding: gzip”的是时候，客户端就会先使用 gzip 对其进行解压，然后把解压后的内容呈现给用户。目前主流的爬虫框架，如”requests”、”Scarpy”都会自动帮你完成这件事，用户对此是毫无感知的。</p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>这次测试压缩用的是 Linux 的 dd 命令，很简单就能实现</p>
<p>首先我们用制作一个 gzip 文件，把其放到待会要开启的 web 服务目录下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo -n &quot;Hello world&quot; | gzip  &gt; data.gz</span><br></pre></td></tr></table></figure>

<p>然后开启一个 web 服务，这个是没有设置”Content-Encoding”头部的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># main.py</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> FileResponse</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>():</span><br><span class="line">    resp = FileResponse(<span class="string">&#x27;data.gz&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> resp</span><br></pre></td></tr></table></figure>

<p>启动网站</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">uvicorn main:app</span><br></pre></td></tr></table></figure>

<p>我们用 requests 访问该网站，发现返回的是乱码，因为响应包的头部并没有设置”Content-Encoding: gzip”，所以并不知道这是压缩后的网站内容，只返回了一串不知名的二进制字符</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; import requests</span><br><span class="line">&gt;&gt;&gt; resp = requests.get(&quot;http://127.0.0.1:8000&quot;).text</span><br><span class="line">&gt;&gt;&gt; resp</span><br><span class="line">&#x27;\x1f�\x08\x00\x00\x00\x00\x00\x00\x03�H���W(�/�I\x01\x00R�\u058b\x0b\x00\x00\x00&#x27;</span><br></pre></td></tr></table></figure>

<p>然后我们修改 main.py，增加头部，然后重启一下服务</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> FileResponse</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>():</span><br><span class="line">    resp = FileResponse(<span class="string">&#x27;data.gz&#x27;</span>)</span><br><span class="line">    <span class="comment"># +</span></span><br><span class="line">    resp.headers[<span class="string">&#x27;Content-Encoding&#x27;</span>] = <span class="string">&#x27;gzip&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> resp</span><br></pre></td></tr></table></figure>

<p>再次用 requests 访问该网站，发现返回的是正常的文件内容了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; import requests</span><br><span class="line">&gt;&gt;&gt; resp = requests.get(&quot;http://127.0.0.1:8000&quot;).text</span><br><span class="line">&gt;&gt;&gt; resp</span><br><span class="line">&#x27;Hello world&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>思路如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">将1G的文件用 gzip 压缩成 1m，然后放到网站上并在网站服务器设置头部，当有人下载该文件时看到的文件大小只有1m，但客户端会将这个1m的文件在内存中还原成1G的内容，然后该爬虫服务器的运行内存瞬间爆涨1G，甚至，我们还可以将这个1G扩大为10G，100G......这样做之后爬虫服务器杀死爬虫进程，重则死机重启。</span><br></pre></td></tr></table></figure>

<ol>
<li>制作一个1GB的 gzip 压缩文件，放到 web 目录</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">dd if=/dev/zero bs=1M count=1000|gzip &gt; boom.gz</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>开一个 web 服务</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> FileResponse</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>():</span><br><span class="line">    resp = FileResponse(<span class="string">&#x27;boom.gz&#x27;</span>)</span><br><span class="line">    resp.headers[<span class="string">&#x27;Content-Encoding&#x27;</span>] = <span class="string">&#x27;gzip&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> resp</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uvicorn main:app</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>简单写一个爬虫程序，执行（然后我的笔记本风扇就响起来了）</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    resp = requests.get(&quot;http://127.0.0.1:8000&quot;)</span><br><span class="line">    with open(&quot;test&quot;, &#x27;wb&#x27;) as f:</span><br><span class="line">        f.write(resp.content)</span><br><span class="line">        </span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>查看下载的文件，发现它已经在内存中还原成1G的样子了，但它在网站服务器里是1Mb的大小，至此实验结束</li>
</ol>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>以后写爬虫得小心一点了QAQ……</p>
]]></content>
      <tags>
        <tag>gzip炸弹</tag>
      </tags>
  </entry>
</search>
